{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import uuid\n",
    "from uuid import UUID\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Page Title is : üç≠Robin Rebeccaüç≠'s Shop - Depop\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service = Service('./chromedriver'))\n",
    "driver.get(\"https://www.depop.com\")\n",
    "    \n",
    "# class UUIDEncoder(json.JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if isinstance(obj, UUID):\n",
    "#             # if the obj is uuid, we simply return the value of uuid\n",
    "#             return obj.hex\n",
    "#         return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "class Scrapper:\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        try:\n",
    "            driver.find_element(by=By.CSS_SELECTOR, value=\"button[class='sc-kEqXSa sc-iqAclL sc-ciSkZP hQtFsL cmWQHQ exduyW']\").click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"no (accept cookies button) found\")\n",
    "\n",
    "    def nav_by_search(self, search_item):\n",
    "        search_url = \"https://www.depop.com/search/?q=\"+search_item\n",
    "        driver.get(search_url)\n",
    "\n",
    "    def nav_by_shop(self, shop_name):\n",
    "        shop_url = \"https://www.depop.com/\"+shop_name\n",
    "        driver.get(shop_url)\n",
    "\n",
    "    def header_url_list(self):\n",
    "        header_url = []\n",
    "        top_level_elements = driver.find_elements(by=By.CLASS_NAME, value=\"styles__NavigationItem-sc-__sc-10mkzda-3\")\n",
    "        for i in top_level_elements:\n",
    "            try:\n",
    "                child_level_elements = i.find_elements(by=By.XPATH, value=\".//div/ul/li\")\n",
    "                for j in child_level_elements:\n",
    "                    child_nav_option = j.find_element(by=By.XPATH, value=\".//a\").get_attribute(\"href\")\n",
    "                    header_url.append(child_nav_option)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "        return header_url\n",
    "\n",
    "\n",
    "    def listing_url(self, listing_no):\n",
    "        listing = driver.find_elements(by=By.CLASS_NAME, value=\"styles__ProductCardContainer-sc-__sc-13q41bc-8\")\n",
    "        listing_url = listing[listing_no].find_element(by=By.XPATH, value=\".//a\").get_attribute(\"href\")\n",
    "        return listing_url\n",
    "\n",
    "    def scroll_to_bottom(self):\n",
    "        webpage_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        current_height = 0\n",
    "        while current_height <= webpage_height:\n",
    "            driver.execute_script(\"window.scrollTo(0,\"+str(current_height)+\")\")\n",
    "            current_height += 30\n",
    "\n",
    "    def back_page(self):\n",
    "        driver.execute_script(\"window.history.go(-1)\")\n",
    "\n",
    "    def open_url_new_tab(self, url):\n",
    "        driver.execute_script(\"window.open('\" + url + \"');\")\n",
    "\n",
    "    def close_tab(self):\n",
    "        driver.close()\n",
    "\n",
    "    def switch_tab(self, tab_no):\n",
    "        driver.switch_to.window(driver.window_handles[tab_no])\n",
    "\n",
    "    def get_shop_data(self):\n",
    "        data_dictionary={}\n",
    "\n",
    "        username = driver.find_element(by=By.CLASS_NAME, value=\"styles__UserName-sc-__r941b9-4\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Username\": username})\n",
    "        items_sold = driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[1]/div/div[2]/div[1]/p\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Items Sold\": items_sold})\n",
    "        last_activity = driver.find_element(by=By.XPATH, value='//*[@id=\"main\"]/div[1]/div[1]/div/div[2]/div[2]/p').get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Last Activity\": last_activity})\n",
    "        followers = driver.find_element(by=By.XPATH, value='//*[@id=\"main\"]/div[1]/div[2]/button[1]/p[1]').get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Followers\": followers})\n",
    "        following = driver.find_element(by=By.XPATH, value='//*[@id=\"main\"]/div[1]/div[2]/button[2]/p[1]').get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Following\": following})\n",
    "        try:\n",
    "            bio_text = driver.find_element(by=By.XPATH, value='//*[@id=\"main\"]/div[1]/div[3]/p').get_attribute(\"innerText\")\n",
    "        except NoSuchElementException:\n",
    "            bio_text = \"None\"\n",
    "        data_dictionary.update({\"Bio Description\":bio_text})\n",
    "        return data_dictionary        \n",
    "\n",
    "    def product_availability(self):\n",
    "        try:\n",
    "            driver.find_element(by=By.CSS_SELECTOR, value=\"button.egHolT[color='yellow']\")\n",
    "            sold = True\n",
    "        except NoSuchElementException:\n",
    "            sold = False\n",
    "        print(\"Product sold? \"+ str(sold))\n",
    "        return sold\n",
    "\n",
    "\n",
    "    def get_product_page_data(self):\n",
    "\n",
    "        data_dictionary = {}\n",
    "\n",
    "        data_dictionary.update({\"Product ID\": driver.current_url})\n",
    "        data_dictionary.update({\"UUID\": str(uuid.uuid4())})\n",
    "        shop_name = driver.find_element(by=By.CSS_SELECTOR, value=\"a[data-testid='bio__username']\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Shop Name\": shop_name})\n",
    "        postcode = driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[3]/div/div[1]/div[1]/div[1]/div/p\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Location\": postcode})\n",
    "\n",
    "        # rating = 0\n",
    "        # for i in range(1, 5):\n",
    "\n",
    "        #     star = driver.find_element(by=By.XPATH, value=\"//*[@id='feedback-star-\" + str(i) + \"-19262048']/title\").get_attribute(\"innerText\")\n",
    "        #     if star == \"Full Star\":\n",
    "        #         rating += 1\n",
    "        #     elif star == \"Half Star\":\n",
    "        #         rating += 0.5\n",
    "        #     elif star == \"Empty Star\":\n",
    "        #         rating += 0\n",
    "        \n",
    "        review_num = driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[3]/div/div[1]/div[1]/div[1]/div/button/p\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"No. of Reviews\": review_num})\n",
    "        sold_items = driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[3]/div/div[1]/div[1]/div[2]/div[1]/p\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"No. of Items Sold\": sold_items})\n",
    "        activity = driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[3]/div/div[1]/div[1]/div[2]/div[2]/p\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Last Active Date\": activity})\n",
    "\n",
    "        try:\n",
    "            likes_num = driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[3]/div/div[1]/div[2]/span/b\").get_attribute(\"innerText\")\n",
    "        except NoSuchElementException:\n",
    "            likes_num = \"0\"\n",
    "        data_dictionary.update({\"No. of Likes\": likes_num})\n",
    "\n",
    "        price = driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[3]/div/div[2]/div[1]/div/p\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Price\": price})\n",
    "        item_description = driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[3]/div/div[3]/p\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Item Description\": item_description})\n",
    "        last_refresh = driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[3]/div/div[3]/div/time\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Last Update\": last_refresh})\n",
    "\n",
    "        try:\n",
    "            one_size = driver.find_element(by=By.CSS_SELECTOR, value=\"tr[data-testid='product__singleSize']\")\n",
    "            size = one_size.find_element(by=By.XPATH, value=\".//td\").get_attribute(\"innerText\")\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            size = \"Multiple sizes\"\n",
    "        data_dictionary.update({\"Sizes Available\": size})\n",
    "\n",
    "        try:\n",
    "            brand = driver.find_element(by=By.CSS_SELECTOR, value=\"a[data-testid='product__brand']\").get_attribute(\"innerText\")\n",
    "        except NoSuchElementException:\n",
    "            brand = \"None\"\n",
    "        data_dictionary.update({\"Brand\": brand})\n",
    "\n",
    "        condition = driver.find_element(by=By.CSS_SELECTOR, value=\"td[data-testid='product__condition']\").get_attribute(\"innerText\")\n",
    "        data_dictionary.update({\"Item Condition\": condition})\n",
    "\n",
    "        try:\n",
    "            colour = driver.find_element(by=By.CSS_SELECTOR, value=\"td[data-testid='product__colour']\").get_attribute(\"innerText\")\n",
    "        except NoSuchElementException:\n",
    "            colour = \"None\"\n",
    "        data_dictionary.update({\"Colour\": colour})\n",
    "\n",
    "        try:\n",
    "            style_tag = driver.find_element(by=By.CSS_SELECTOR, value=\"td[data-testid='selected__styles']\").get_attribute(\"innerText\")\n",
    "        except NoSuchElementException:\n",
    "            style_tag = \"None\"\n",
    "        data_dictionary.update({\"Style\": style_tag})\n",
    "\n",
    "        img_urls = []\n",
    "        image_elements = driver.find_elements(by=By.CSS_SELECTOR, value=\"img[class='LazyLoadImage__StyledImage-sc-__bquzot-1 doaiRN styles__LazyImage-sc-__sc-1fk4zep-9 hRpLaq']\")\n",
    "        for image_element in image_elements:\n",
    "            img_url = image_element.get_attribute(\"src\")\n",
    "            if img_url not in img_urls:\n",
    "                img_urls.append(img_url)\n",
    "        data_dictionary.update({\"Image Urls\": img_urls})\n",
    "\n",
    "        # print(rating)\n",
    "        return data_dictionary\n",
    "\n",
    "    def scrape_listing(self, number_of_listing):\n",
    "        for i in range(number_of_listing):\n",
    "            if ((i)%24 == 0) and i !=0:\n",
    "                self.scroll_to_bottom()\n",
    "                time.sleep(1)\n",
    "            listing_url = self.listing_url(i)\n",
    "            self.open_url_new_tab(listing_url)\n",
    "            self.switch_tab(1)\n",
    "            self.scroll_to_bottom()\n",
    "            scraped_data = self.get_product_page_data()\n",
    "            self.add_data(scraped_data, \"./raw_data/data.json\", \"Test_ShopData\")\n",
    "            self.close_tab()\n",
    "            self.switch_tab(0)\n",
    "\n",
    "    def create_json_file(self, filepath, main_dictionaries,):\n",
    "        output ={}\n",
    "        for dictionary in main_dictionaries:\n",
    "            output[dictionary]=[]\n",
    "        with open(filepath, \"w\") as outfile:\n",
    "            json.dump(output, outfile)\n",
    "\n",
    "    def add_data(self, new_data, filepath, main_dictionary):\n",
    "        with open(filepath, 'r+') as file:\n",
    "            file_data = json.load(file)\n",
    "            file_data[main_dictionary].append(new_data)\n",
    "            file.seek(0)\n",
    "            json.dump(file_data, file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Scrapper()\n",
    "    # Scrapper.nav_by_search(Scrapper, \"top\")\n",
    "    # Scrapper.nav_by_url(Scrapper, Scrapper.header_url_list(Scrapper)[1])\n",
    "    # Scrapper.scroll_to_bottom(Scrapper)\n",
    "    # Scrapper.back_page(Scrapper)\n",
    "    # Scrapper.open_url_new_tab(Scrapper, Scrapper.nav_listing(Scrapper, 2))\n",
    "    # Scrapper.switch_tab(Scrapper, 0)\n",
    "    # Scrapper.close_tab(Scrapper)\n",
    "\n",
    "bot = Scrapper()\n",
    "bot.nav_by_shop(\"robinrebecca\")\n",
    "print(\"Current Page Title is : %s\" %driver.title)\n",
    "bot.create_json_file(\"./raw_data/data.json\", [\"HI\"])\n",
    "bot.scrape_listing(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(str(True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Page Title is : üç≠Robin Rebeccaüç≠'s Shop - Depop\n",
      "@robinrebecca\n",
      "9461 sold\n",
      "Active today\n",
      "32K\n",
      "157\n",
      "‚úÖ Instant buy is on ‚ùå No returns/refunds üá¨üáß Delivery 1-4 working days üåé Worldwide shipping available üíå Message for 1st class\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service = Service('./chromedriver'))\n",
    "driver.get(\"https://www.depop.com/robinrebecca\")\n",
    "\n",
    "bot = Scrapper()\n",
    "print(\"Current Page Title is : %s\" %driver.title)\n",
    "# <p data-testid=\"username\" type=\"caption1\" class=\"sc-jrsJWt styles__UserName-sc-__r941b9-4 eoZhdh dYxTjP\">@robinrebecca</p>\n",
    "# print(driver.find_element(by=By.CLASS_NAME, value=\"styles__FullName-sc-__r941b9-3\").get_attribute(\"innerText\"))\n",
    "print(driver.find_element(by=By.CLASS_NAME, value=\"styles__UserName-sc-__r941b9-4\").get_attribute(\"innerText\"))\n",
    "print(driver.find_element(by=By.XPATH, value=\"//*[@id='main']/div[1]/div[1]/div/div[2]/div[1]/p\").get_attribute(\"innerText\"))\n",
    "print(driver.find_element(by=By.XPATH, value='//*[@id=\"main\"]/div[1]/div[1]/div/div[2]/div[2]/p').get_attribute(\"innerText\"))\n",
    "print(driver.find_element(by=By.XPATH, value='//*[@id=\"main\"]/div[1]/div[2]/button[1]/p[1]').get_attribute(\"innerText\"))\n",
    "print(driver.find_element(by=By.XPATH, value='//*[@id=\"main\"]/div[1]/div[2]/button[2]/p[1]').get_attribute(\"innerText\"))\n",
    "print(driver.find_element(by=By.XPATH, value='//*[@id=\"main\"]/div[1]/div[3]/p').get_attribute(\"innerText\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# //*[@id=\"main\"]/div[1]/div[1]/div/div[2]/div[2]/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={\"name\": \"hi\", \"we\":\"no\"}\n",
    "\n",
    "with open(\"./raw_data/data.json\", \"r+\") as file:\n",
    "    file_data = json.load(file)\n",
    "    file_data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hi': 0}\n"
     ]
    }
   ],
   "source": [
    "dict = {}\n",
    "dict[\"hi\"] = 0\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hi': []}\n",
      "{'hi': [], 'bye': []}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/html/body/div/div/div/div[1]/div[3]/div/div[1]/div[1]/div[1]/div/button/span/svg[1]/title\n",
      "/html/body/div/div/div/div[1]/div[3]/div/div[1]/div[1]/div[1]/div/button/span/svg[2]/title\n",
      "/html/body/div/div/div/div[1]/div[3]/div/div[1]/div[1]/div[1]/div/button/span/svg[3]/title\n",
      "/html/body/div/div/div/div[1]/div[3]/div/div[1]/div[1]/div[1]/div/button/span/svg[4]/title\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    a = \"/html/body/div/div/div/div[1]/div[3]/div/div[1]/div[1]/div[1]/div/button/span/svg[\"+ str(i) +\"]/title\"\n",
    "    print(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59a815aa6b510b7c00ae6aa3124b3da72856d47b254de79486eb33c0d94934ee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('data-collection-pipeline-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
